{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import random \n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from torch_geometric.nn import NNConv\n",
    "from torch.nn import Linear\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_polygon(n, radius=1):\n",
    "    node_pos = [(radius * np.cos(2 * np.pi * i / n),\n",
    "                 radius * np.sin(2 * np.pi * i / n)) for i in range(n)]\n",
    "    x = torch.tensor(node_pos,dtype=torch.float)\n",
    "    return x\n",
    "\n",
    "def generate_randPos(n, radius=1):\n",
    "    node_pos = [(random.uniform(-1, 1),\n",
    "                 random.uniform(-1, 1)) for i in range(n)]\n",
    "    x = torch.tensor(node_pos,dtype=torch.float)\n",
    "    return x\n",
    "\n",
    "def generate_edgelist(size):\n",
    "    return [(i, j) for i in range(size) for j in range(i + 1, size)]\n",
    "\n",
    "def node2edge(node_pos, batch):\n",
    "    # find sizes for each graph in batch\n",
    "    graph_sizes = list(map(lambda d: d.x.size()[0], batch.to_data_list()))\n",
    "    # get split indices\n",
    "    start_idx = np.insert(np.cumsum(graph_sizes), 0, 0)\n",
    "    start_pos = []\n",
    "    end_pos = []\n",
    "    for i, num_nodes in enumerate(graph_sizes):\n",
    "        # get edge list for current graph\n",
    "        edgelist = np.array(generate_edgelist(num_nodes))\n",
    "        # get node positions for current graph\n",
    "        graph_node_pos = node_pos[start_idx[i]:start_idx[i+1]]\n",
    "        # get edge start positions for current graph\n",
    "        start_pos += [graph_node_pos[edgelist[:, 0]]]\n",
    "        # get edge end positions for current graph\n",
    "        end_pos += [graph_node_pos[edgelist[:, 1]]]\n",
    "    # concatenate the results\n",
    "    return torch.cat(start_pos, 0), torch.cat(end_pos, 0)\n",
    "\n",
    "def generate_eAttr(G, com_edge_list):\n",
    "    path_length = dict(nx.all_pairs_shortest_path_length(G))\n",
    "    max_length = 0\n",
    "    for source in path_length:\n",
    "        for target in path_length[source]:\n",
    "            if path_length[source][target] > max_length:\n",
    "                max_length = path_length[source][target]\n",
    "    L = 2/max_length\n",
    "    K = 1\n",
    "    edge_attr = []\n",
    "    for i in com_edge_list:\n",
    "        start = \"n\" + str(i[0])\n",
    "        end = \"n\" + str(i[1])\n",
    "        d = path_length[start][end]\n",
    "        l = L * d #l = L * d\n",
    "        k = K/(d**2) \n",
    "#         start_degree = G.degree(start)\n",
    "#         end_degree = G.degree(end)\n",
    "        edge_attr.append([l,k])\n",
    "    out = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    return out\n",
    "\n",
    "def generate_graph(size):\n",
    "    while True:\n",
    "        G = nx.binomial_graph(size, random.uniform(0,0.2),directed=False)\n",
    "#         G = nx.random_powerlaw_tree(size,3,tries=10000)\n",
    "        com_edge_list = generate_edgelist(size)\n",
    "        try:\n",
    "            edge_attr = generate_eAttr(G, com_edge_list)\n",
    "        except KeyError:\n",
    "            continue\n",
    "        except ZeroDivisionError:\n",
    "            continue\n",
    "#         nx.write_edgelist(G, file_name, data=False)\n",
    "        edge_index = torch.tensor(com_edge_list, dtype=torch.long)\n",
    "        x = generate_randPos(size)\n",
    "        data = Data(x=x, edge_index=edge_index.t().contiguous(), edge_attr=edge_attr)\n",
    "        return G, data\n",
    "\n",
    "def generate_testgraph(size,prob):\n",
    "    while True:\n",
    "        G = nx.binomial_graph(size, prob,directed=False)\n",
    "#         G = nx.random_powerlaw_tree(size,3,tries=10000)\n",
    "        com_edge_list = generate_edgelist(size)\n",
    "        try:\n",
    "            edge_attr = generate_eAttr(G, com_edge_list)\n",
    "        except KeyError:\n",
    "            continue\n",
    "        except ZeroDivisionError:\n",
    "            continue\n",
    "#         nx.write_edgelist(G, file_name, data=False)\n",
    "        edge_index = torch.tensor(com_edge_list, dtype=torch.long)\n",
    "        x = generate_randPos(size)\n",
    "        data = Data(x=x, edge_index=edge_index.t().contiguous(), edge_attr=edge_attr)\n",
    "        return G, data\n",
    "\n",
    "class EnergyLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, p, data_batch):\n",
    "        energy = 0\n",
    "        offset = 0\n",
    "        for data in data_batch.to_data_list():\n",
    "            edge_attr = data.edge_attr\n",
    "            n = data.x.size()[0]\n",
    "            x = p[offset:offset+n, 0]\n",
    "            y = p[offset:offset+n, 1]\n",
    "            offset += n\n",
    "            l = edge_attr[:, 0]\n",
    "            k = edge_attr[:, 1]\n",
    "            for e, (i, j) in enumerate(generate_edgelist(n)):\n",
    "                term1 = (x[i] - x[j]) ** 2\n",
    "                term2 = (y[i] - y[j]) ** 2\n",
    "                term3 = l[e] ** 2\n",
    "                term4 = 2 * l[e] * (term1 + term2).sqrt()\n",
    "                energy += k[e] / 2 * (term1 + term2 + term3 - term4)\n",
    "        return energy\n",
    "\n",
    "    \n",
    "class EnergyLossVectorized(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, p, data):\n",
    "        edge_attr = data.edge_attr\n",
    "        # convert per-node positions to per-edge positions\n",
    "        start, end = node2edge(p, data)\n",
    "        \n",
    "        start_x = start[:, 0]\n",
    "        start_y = start[:, 1]\n",
    "        end_x = end[:, 0]\n",
    "        end_y = end[:, 1]\n",
    "        \n",
    "        l = edge_attr[:, 0]\n",
    "        k = edge_attr[:, 1]\n",
    "        \n",
    "        term1 = (start_x - end_x) ** 2\n",
    "        term2 = (start_y - end_y) ** 2\n",
    "        term3 = l ** 2\n",
    "        term4 = 2 * l * (term1 + term2).sqrt()\n",
    "        energy = k / 2 * (term1 + term2 + term3 - term4)\n",
    "        return energy.sum()\n",
    "    \n",
    "def train(model, criterion, optimizer,loader):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output,data)\n",
    "        loss.backward()\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        optimizer.step()\n",
    "    return loss_all / len(data_list)\n",
    "\n",
    "def evaluate(model,data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        pred = model(data).detach().cpu().numpy()\n",
    "    return pred\n",
    "\n",
    "def load_rome(ngraph):\n",
    "    files = glob.glob('rome/*.graphml')\n",
    "    random.shuffle(files)\n",
    "    G_list = []\n",
    "    count = 0\n",
    "    for file in files:\n",
    "        G = nx.read_graphml(file)\n",
    "        G_list.append(G)\n",
    "    return G_list\n",
    "\n",
    "def graph_vis(G, node_pos, file_name):\n",
    "    i = 0\n",
    "    for n, p in node_pos:\n",
    "        node = 'n' +str(i)\n",
    "        G.nodes[node]['pos'] = (n,p)\n",
    "        i += 1\n",
    "    pos = nx.get_node_attributes(G,'pos')\n",
    "    plt.figure()\n",
    "    nx.draw(G, pos)\n",
    "    plt.savefig(file_name) \n",
    "    \n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = NNConv(2, 16, Linear(2,2*16))\n",
    "        self.conv2 = NNConv(16, 16, Linear(2, 16*16))\n",
    "        self.conv3 = NNConv(4*16, 2, Linear(2, 4*16*2))\n",
    "        self.relu = nn.LeakyReLU()\n",
    "#         self.conv4 = NNConv(16+32+64, 128, Linear(2, (16+32+64)*128))\n",
    "#         self.conv5 = NNConv(128,2,Linear(2,128*2))\n",
    "#         self.conv2 = NNConv(16,2,Linear(2,16*2))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        x1 = self.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x2 = self.relu(self.conv2(x1, edge_index, edge_attr))\n",
    "        x3 = self.relu(self.conv2(x2, edge_index, edge_attr))\n",
    "        x4 = self.relu(self.conv2(x3, edge_index, edge_attr))\n",
    "        x5 = torch.cat((x1, x2, x3, x4), dim=1)\n",
    "        x6 = self.conv3(x5, edge_index, edge_attr)\n",
    "#         x2 = F.relu(self.conv2(x1, edge_index, edge_attr))\n",
    "#         x3 = F.relu(self.conv3(x2, edge_index, edge_attr))\n",
    "        \n",
    "#         x4 = F.relu(self.conv4(x, edge_index, edge_attr))\n",
    "#         x5 = F.relu(self.conv5(x4,edge_index,edge_attr))\n",
    "        return x6\n",
    "\n",
    "\n",
    "def convert_datalist(rome,ngraph):\n",
    "    count = 0\n",
    "    data_list = []\n",
    "    G_list = []\n",
    "    for G in rome:\n",
    "        com_edge_list = generate_edgelist(G.size())\n",
    "        try:\n",
    "            edge_attr = generate_eAttr(G, com_edge_list)\n",
    "        except KeyError:\n",
    "            continue\n",
    "        except ZeroDivisionError:\n",
    "            continue\n",
    "        edge_index = torch.tensor(com_edge_list, dtype=torch.long)\n",
    "        x = generate_randPos(G.size())\n",
    "        data = Data(x=x, edge_index=edge_index.t().contiguous(), edge_attr=edge_attr)\n",
    "        count += 1\n",
    "        print(count)\n",
    "        data_list.append(data)\n",
    "        G_list.append(G)\n",
    "        if count >= ngraph:\n",
    "            return G_list,data_list\n",
    "    return G_list,data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate random graph\n",
    "ngraph = 1000\n",
    "ngraph_size = [random.randint(20,40) for i in range(ngraph)]\n",
    "data_list = []\n",
    "for i in range(ngraph):\n",
    "    G, data = generate_graph(ngraph_size[i])\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load specific number of graph from rome dataset\n",
    "ngraph = 1000\n",
    "rome = load_rome(ngraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n"
     ]
    }
   ],
   "source": [
    "G_list,data_list = convert_datalist(rome,ngraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(data_list[:-1], batch_size=32,shuffle=True)\n",
    "loss_ep = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 74.90252758730516\n",
      "250 33.06200118030576\n",
      "260 24.22832139561788\n",
      "270 18.363741575099297\n",
      "280 17.23008768278346\n",
      "290 16.6541098907983\n",
      "300 15.998898000740033\n",
      "310 15.048398610213392\n",
      "320 14.314259554270645\n",
      "330 13.930450951738608\n",
      "340 13.636032214267649\n",
      "350 13.483302786481753\n",
      "360 13.384773675200465\n",
      "370 13.114897876620578\n",
      "380 13.010408470098922\n",
      "390 12.848615028875336\n",
      "400 12.723574924240296\n",
      "410 12.629533946085319\n",
      "420 12.627439576658986\n",
      "430 12.43625551219181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:176: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440 12.319976660273344\n",
      "450 12.190673389023157\n",
      "460 12.135894848574265\n",
      "470 11.988342138788969\n",
      "480 11.88027024669327\n",
      "490 11.728838877140475\n",
      "500 11.60240081860293\n",
      "510 11.47316085120185\n",
      "520 11.395127989405351\n",
      "530 11.268497750627622\n",
      "540 11.224069865201589\n",
      "550 11.09853064813774\n",
      "560 11.011774186607745\n",
      "570 10.930358008515062\n",
      "580 10.904987984709889\n",
      "590 10.842285595351843\n",
      "600 10.774589044584644\n",
      "610 10.722531325525518\n",
      "620 10.593177338012403\n",
      "630 10.573867907627024\n",
      "640 10.448998174507269\n",
      "650 10.416913881004572\n",
      "660 10.343283381107614\n",
      "670 10.30586963534641\n",
      "680 10.279464428945126\n",
      "690 10.23279320879234\n",
      "700 10.191010911973546\n",
      "710 10.182652388831123\n",
      "720 10.100991521236136\n",
      "730 10.070729134465864\n",
      "740 10.02951854824734\n",
      "750 9.986602966162227\n",
      "760 9.937431646479691\n",
      "770 9.919013300102106\n",
      "780 9.87257242545807\n",
      "790 9.861842679176972\n",
      "800 9.810151902891748\n",
      "810 9.787185266435289\n",
      "820 9.779145384863984\n",
      "830 9.766839153189167\n",
      "840 9.748372469016974\n",
      "850 9.67923661559034\n",
      "860 9.676274105227536\n",
      "870 9.650732465785184\n",
      "880 9.64355838327385\n",
      "890 9.634195304888902\n",
      "900 9.596230486314074\n",
      "910 9.57700748580823\n",
      "920 9.568185454078144\n",
      "930 9.576156213700914\n",
      "940 9.538758348789719\n",
      "950 9.512873404889369\n",
      "960 9.503693797891374\n",
      "970 9.494373385568888\n",
      "980 9.480555253063175\n",
      "990 9.466538573340546\n",
      "1000 9.469409896887178\n",
      "1010 9.458294765554744\n",
      "1020 9.448205522496066\n",
      "1030 9.429978039053132\n",
      "1040 9.41216543366869\n",
      "1050 9.396252968328461\n",
      "1060 9.400148131006913\n",
      "1070 9.384033678818664\n",
      "1080 9.365996289882156\n",
      "1090 9.356819793188887\n",
      "1100 9.371584263351037\n",
      "1110 9.346472614388958\n",
      "1120 9.331391222471241\n",
      "1130 9.332720347159773\n",
      "1140 9.308213341436225\n",
      "1150 9.302289967342531\n",
      "1160 9.295503209249008\n",
      "1170 9.282510807760042\n",
      "1180 9.296839066832472\n",
      "1190 9.272377800884293\n",
      "1200 9.263527483677121\n",
      "1210 9.257310021123725\n",
      "1220 9.25358343696137\n",
      "1230 9.242124342518172\n",
      "1240 9.238744136526716\n",
      "1250 9.232150875978904\n",
      "1260 9.227206845363552\n",
      "1270 9.215748299797662\n",
      "1280 9.209827084621365\n",
      "1290 9.205705016065274\n",
      "1300 9.206518671781325\n",
      "1310 9.198586809263526\n",
      "1320 9.194718797715733\n",
      "1330 9.189723977653815\n",
      "1340 9.182590219328443\n",
      "1350 9.176627289477013\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 240\n",
    "num_epochs = 11000\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if start_epoch == 1:\n",
    "    model = Net().to(device)\n",
    "else:\n",
    "    model = torch.load(f'ckpt_rome_nodegree/epoch_{start_epoch}.pt').to(device)\n",
    "criterion = EnergyLossVectorized()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 100, 0.8)\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    loss = train(model, criterion, optimizer,loader)\n",
    "    loss_ep.append(loss)\n",
    "    scheduler.step()\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model, f'ckpt_rome_nodegree/epoch_{epoch}.pt')\n",
    "        node_pos = evaluate(model, data_list[-1])\n",
    "        graph_vis(G_list[-1], node_pos, f'rome_nodegree/epoch_{epoch}.png')\n",
    "        print(epoch, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_vis = G_list[5]\n",
    "node_pos = evaluate(model, data_list[5])\n",
    "graph_vis(G_vis, node_pos, f'train.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pygraphviz/agraph.py:1341: RuntimeWarning: Error: node n0, position (-0.0064143543, -0.0063243043), expected two doubles\n",
      "Error: node n3, position (-0.0061180475, -0.0060748463), expected two doubles\n",
      "Error: node n6, position (-0.0055141607, -0.0057177194), expected two doubles\n",
      "Error: node n1, position (-0.0063391873, -0.006245218), expected two doubles\n",
      "Error: node n11, position (-0.0038200922, -0.004810504), expected two doubles\n",
      "Error: node n2, position (-0.0061928025, -0.0061162403), expected two doubles\n",
      "Error: node n7, position (-0.0051588244, -0.005475289), expected two doubles\n",
      "Error: node n8, position (-0.0048318203, -0.005267361), expected two doubles\n",
      "Error: node n9, position (-0.0044840835, -0.0050721904), expected two doubles\n",
      "Error: node n10, position (-0.0041830773, -0.0049435515), expected two doubles\n",
      "Error: node n4, position (-0.005950516, -0.005981956), expected two doubles\n",
      "Error: node n5, position (-0.0057547507, -0.0058634914), expected two doubles\n",
      "\n",
      "  warnings.warn(b\"\".join(errors).decode(self.encoding), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from networkx.drawing.nx_agraph import graphviz_layout, to_agraph\n",
    "import pygraphviz as pgv\n",
    "A = to_agraph(G_list[380])\n",
    "A.layout('neato')\n",
    "A.draw('380.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(loss_ep[:1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
