{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **[edge attr]** *euclidean and normalized direction* \n",
    "## **[edge net]** *2 layers*\n",
    "## **[block dim]** *8,8,8,8*\n",
    "## **[num blocks]** *9*\n",
    "## **[init pos]** *scaled random*\n",
    "## **[loss]** *RatioStressLoss:1, NormalizedL1AngularLoss:0.5*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from modules import *\n",
    "from ipynb.fs.defs.losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_idx = None\n",
    "config = Config('gnn_stress-template.json')\n",
    "loss_fns = {\n",
    "    RatioStressLoss(): 1, \n",
    "    NormalizedL1AngularLoss(): 1\n",
    "}\n",
    "model_params = {\n",
    "    \"num_blocks\": 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'template_experiment',\n",
       " 'batchsize': 128,\n",
       " 'epoch': {'start': 0, 'end': None},\n",
       " 'lr': {'initial': 0.01,\n",
       "  'decay_rate': 0.99,\n",
       "  'decay_step': 1,\n",
       "  'override': {'start_epoch': None,\n",
       "   'target_lr': None,\n",
       "   'decay_rate': None,\n",
       "   'decay_step': None}},\n",
       " 'log_period': 1,\n",
       " 'test': {'name': 'test', 'epoch': 505}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /home/jupyter/graph-drawing-stress\n",
      "tail -f template_experiment.log\n"
     ]
    }
   ],
   "source": [
    "print(f\"cd {os.getcwd()}\")\n",
    "print(f\"tail -f {config.name}.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = f'cuda:{cuda_idx}' if cuda_idx is not None and torch.cuda.is_available() else 'cpu'\n",
    "nvidia_smi.nvmlInit()\n",
    "cuda = nvidia_smi.nvmlDeviceGetHandleByIndex(cuda_idx) if cuda_idx is not None else None\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_lambda(epoch):\n",
    "    current_epoch = config.epoch.start + epoch\n",
    "    if config.lr.override.start_epoch is not None and current_epoch >= config.lr.override.start_epoch:\n",
    "        num_step = (current_epoch - config.lr.override.start_epoch) // config.lr.override.decay_step\n",
    "        return config.lr.override.target_lr * config.lr.override.decay_rate ** num_step\n",
    "    num_step = current_epoch // config.lr.decay_step\n",
    "    return config.lr.initial * config.lr.decay_rate ** num_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_callback(*, output, loss, components):\n",
    "    postfix = {'loss': loss.item()}\n",
    "    if cuda is not None:\n",
    "        util_info = nvidia_smi.nvmlDeviceGetUtilizationRates(cuda)\n",
    "        mem_info = nvidia_smi.nvmlDeviceGetMemoryInfo(cuda)\n",
    "        postfix['gpu%'] = util_info.gpu\n",
    "        postfix['mem%'] = mem_info.used / mem_info.total * 100\n",
    "    progress.update()\n",
    "    progress.set_postfix(postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_list, data_list = load_processed_data(G_list_file='G_list_1.pickle', \n",
    "                                        data_list_file='data_list_1.pickle',\n",
    "                                        index_file='data_index_1.txt')\n",
    "train_loader = DataLoader(data_list[:10000], batch_size=config.batchsize, shuffle=True)\n",
    "val_loader = DataLoader(data_list[11000:], batch_size=config.batchsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CompositeLoss([fn for fn in loss_fns], weights=[loss_fns[fn] for fn in loss_fns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e765463bde4ed1b4bd4ceb6c527a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not os.path.isdir(f\"../ckpt_{config.name}\"):\n",
    "    os.mkdir(f\"../ckpt_{config.name}\")\n",
    "model = Model(**model_params).to(device)\n",
    "if config.epoch.start > 0:\n",
    "    state_dict = torch.load(f\"../ckpt_{config.name}/epoch_{config.epoch.start}.pt\")\n",
    "    model.load_state_dict(state_dict)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=lr_lambda)\n",
    "print(\"=\" * 50, file=open(f\"{config.name}.log\", \"a\"))\n",
    "epoch = config.epoch.start + 1\n",
    "with tqdm(total=len(train_loader), smoothing=0) as progress:\n",
    "    while True:\n",
    "        progress.reset()\n",
    "        progress.set_description(desc=f\"[epoch {epoch}/{config.epoch.end}]\")\n",
    "        train_loss, train_loss_comp = train(model=model, \n",
    "                                            criterion=criterion, \n",
    "                                            optimizer=optimizer,\n",
    "                                            data_loader=train_loader, \n",
    "                                            callback=train_callback)\n",
    "        scheduler.step()\n",
    "        if epoch % config.log_period == 0:\n",
    "            torch.save(model.state_dict(), f\"../ckpt_{config.name}/epoch_{epoch}.pt\")\n",
    "            val_loss, val_loss_comp = test(model=model, \n",
    "                                           criterion=criterion,\n",
    "                                           data_loader=train_loader)\n",
    "            print(f'{epoch}, train: {train_loss:.2f} {train_loss_comp}, val: {val_loss:.2f} {val_loss_comp}, lr: {scheduler.get_last_lr()[0]:.2e}', \n",
    "                  file=open(f\"{config.name}.log\", \"a\"))\n",
    "        if epoch == config.epoch.end:\n",
    "            break\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f'../ckpt_{config.name}/epoch_{config.test.epoch}.pt', map_location=torch.device(device))\n",
    "criterion = CompositeLoss([EnergyLossVectorized(), AngularResolutionL2Loss()], weights=[0.1, 0.9])\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv('scaled_gt_loss.csv', index_col=0)\n",
    "folder_name = f'{config.name}_{config.test.name}'\n",
    "if not os.path.isdir(folder_name):\n",
    "    os.mkdir(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = CompositeLoss([fn() for fn in loss_fns], weights=[loss_fns[fn] for fn in loss_fns])\n",
    "folder_name = f'{config.name}_{config.test.name}'\n",
    "test_loss = []\n",
    "test_loss_ratio=[]\n",
    "reso_scores = []\n",
    "ring_loss = []\n",
    "reso_loss=[]\n",
    "minOfMin = []\n",
    "for test_idx in tqdm(range(10000,11000)):\n",
    "    G = G_list[test_idx]\n",
    "    data = data_list[test_idx]\n",
    "    node_pos, loss,component = evaluate(model, data, criterion, device,output_components=True)\n",
    "    node_pos_tensor = torch.tensor(node_pos).to(device)\n",
    "#     node_pos_tensor = rescale_with_minimized_stress(node_pos_tensor, data)\n",
    "    loss = criterion(node_pos_tensor, data)\n",
    "    theta,degree,u = get_theta_angles_and_node_degrees(node_pos_tensor, data,return_u=True)\n",
    "    gt_loss = ground_truth.loc[test_idx][0]\n",
    "    loss_ratio = (component[0] - gt_loss) / gt_loss\n",
    "    minDegree = (theta.min().item()/(2*np.pi))*360\n",
    "    minOfMin.append(minDegree)\n",
    "    score = resolution_score(theta,degree,u)\n",
    "    test_loss.append(component[0])\n",
    "    reso_scores.append(score) \n",
    "    reso_loss.append(component[1])\n",
    "    test_loss_ratio.append(loss_ratio)\n",
    "    \n",
    "    graph_vis(G, node_pos, f'{folder_name}/{test_idx}_{component[0]:.2f}_{score:.2f}.png')  \n",
    "#     node_pos = nx.nx_agraph.graphviz_layout(G_vis, prog='neato')\n",
    "#     plt.figure()\n",
    "#     nx.draw(G_vis, node_pos)\n",
    "#     plt.savefig(f'{folder_name}/{test_idx}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"stress\", np.nanmean(test_loss), np.nanstd(test_loss))\n",
    "print(\"reso loss\", np.nanmean(reso_loss), np.nanstd(reso_loss))\n",
    "print(\"score\",np.nanmean(reso_scores), np.nanstd(reso_scores))\n",
    "print(\"min degree\", np.nanmean(minOfMin), np.nanstd(minOfMin))\n",
    "print(\"loss ratio\", torch.tensor(test_loss_ratio).mean(), torch.tensor(test_loss_ratio).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"stress\", np.nanmean(test_loss), np.nanstd(test_loss))\n",
    "print(\"reso loss\", np.nanmean(reso_loss), np.nanstd(reso_loss))\n",
    "print(\"score\",np.nanmean(reso_scores), np.nanstd(reso_scores))\n",
    "print(\"min degree\", np.nanmean(minOfMin), np.nanstd(minOfMin))\n",
    "print(\"loss ratio\", torch.tensor(test_loss_ratio).mean(), torch.tensor(test_loss_ratio).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CompositeLoss([fn() for fn in loss_fns], weights=[loss_fns[fn] for fn in loss_fns])\n",
    "folder_name = f'{config.name}_{config.test.name}'\n",
    "test_loss = []\n",
    "test_loss_ratio=[]\n",
    "reso_scores = []\n",
    "ring_loss = []\n",
    "reso_loss=[]\n",
    "minOfMin = []\n",
    "for test_idx in tqdm(range(10000)):\n",
    "    G = G_list[test_idx]\n",
    "    data = data_list[test_idx]\n",
    "    node_pos, loss,component = evaluate(model, data, criterion, device,output_components=True)\n",
    "    node_pos_tensor = torch.tensor(node_pos).to(device)\n",
    "#     node_pos_tensor = rescale_with_minimized_stress(node_pos_tensor, data)\n",
    "    loss = criterion(node_pos_tensor, data)\n",
    "    theta,degree,u = get_theta_angles_and_node_degrees(node_pos_tensor, data,return_u=True)\n",
    "    gt_loss = ground_truth.loc[test_idx][0]\n",
    "    loss_ratio = (component[0] - gt_loss) / gt_loss\n",
    "    minDegree = (theta.min().item()/(2*np.pi))*360\n",
    "    minOfMin.append(minDegree)\n",
    "    score = resolution_score(theta,degree,u)\n",
    "    test_loss.append(component[0])\n",
    "    reso_scores.append(score) \n",
    "    reso_loss.append(component[1])\n",
    "    test_loss_ratio.append(loss_ratio)\n",
    "    \n",
    "#     graph_vis(G, node_pos, f'{folder_name}/{test_idx}_{component[0]:.2f}_{score:.2f}.png')  \n",
    "#     node_pos = nx.nx_agraph.graphviz_layout(G_vis, prog='neato')\n",
    "#     plt.figure()\n",
    "#     nx.draw(G_vis, node_pos)\n",
    "#     plt.savefig(f'{folder_name}/{test_idx}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"stress\", np.nanmean(test_loss), np.nanstd(test_loss))\n",
    "print(\"reso loss\", np.nanmean(reso_loss), np.nanstd(reso_loss))\n",
    "print(\"score\",np.nanmean(reso_scores), np.nanstd(reso_scores))\n",
    "print(\"min degree\", np.nanmean(minOfMin), np.nanstd(minOfMin))\n",
    "print(\"loss ratio\", torch.tensor(test_loss_ratio).mean(), torch.tensor(test_loss_ratio).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "state_dict = torch.load(f\"../ckpt_{config.name}/epoch_{config.test.epoch}.pt\",map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "test_idx = 10226\n",
    "G = G_list[test_idx]\n",
    "data = data_list[test_idx]\n",
    "criterion = CompositeLoss([StressLoss(),AngularResolutionMAELossRescale()])\n",
    "node_pos, loss,component = evaluate(model, data, criterion, device,output_components=True)\n",
    "graph_vis(G, node_pos,node_size=600, with_labels=True, font_color=\"white\", font_weight=\"bold\", font_size=14) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "loss_ratios = []\n",
    "for test_idx in tqdm(range(10000, 11000)):\n",
    "    G_vis = G_list[test_idx]\n",
    "    node_pos, loss = evaluate(model, data_list[test_idx], criterion, device)\n",
    "    gt_loss = ground_truth.loc[test_idx][0]\n",
    "    loss_ratio = (loss - gt_loss) / gt_loss\n",
    "    losses += [loss]\n",
    "    loss_ratios += [loss_ratio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(losses), np.std(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(loss_ratios), np.std(loss_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_loss = 0\n",
    "pred_loss = 0\n",
    "for idx in tqdm(range(10000, 11000)):\n",
    "    pred, loss = evaluate(model, data_list[idx], criterion, device)\n",
    "    pos_map = nx.nx_agraph.graphviz_layout(G_list[idx], prog='neato')\n",
    "\n",
    "    pred_mean, pred_std = pred.mean(axis=0), pred.std()\n",
    "    truth = np.array(list(pos_map.values()))\n",
    "    truth_mean, truth_std = truth.mean(axis=0), truth.std()\n",
    "    norm_truth = (truth - truth_mean) / truth_std\n",
    "    scaled_truth = norm_truth * pred_std + pred_mean\n",
    "\n",
    "    truth_loss += criterion(torch.tensor(scaled_truth), data_list[idx])\n",
    "    pred_loss += criterion(torch.tensor(pred), data_list[idx])\n",
    "    \n",
    "truth_loss / 1000, pred_loss / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data_list[9999].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 5\n",
    "losses = []\n",
    "folder_name = f'{config.name}_{config.test.name}_iterative'\n",
    "for test_idx in tqdm(range(10000, len(G_list))):\n",
    "    G_vis = G_list[test_idx]\n",
    "    node_pos = nx.nx_agraph.graphviz_layout(G_vis, prog='neato')\n",
    "    plt.figure()\n",
    "    nx.draw(G_vis, node_pos)\n",
    "    plt.savefig(f'{folder_name}/{test_idx}.png')\n",
    "    for i in range(iterations):\n",
    "        node_pos, loss = evaluate(model, data_list[test_idx], criterion, device) \n",
    "        data_list[test_idx].x = torch.tensor(node_pos,dtype=torch.float)\n",
    "    losses += [loss]\n",
    "    graph_vis(G_vis, node_pos, f'{folder_name}/{config.test.out_prefix}_iter_model_{test_idx}_{loss}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(loss_ep[:1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnergyLossScaled(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, p, data, scale):\n",
    "        edge_attr = data.edge_attr\n",
    "        # convert per-node positions to per-edge positions\n",
    "        start, end, n_nodes = node2edge(p, data)\n",
    "        \n",
    "        start *= scale\n",
    "        end *= scale\n",
    "        \n",
    "        start_x = start[:, 0]\n",
    "        start_y = start[:, 1]\n",
    "        end_x = end[:, 0]\n",
    "        end_y = end[:, 1]\n",
    "        \n",
    "        l = edge_attr[:, 0]\n",
    "        k = edge_attr[:, 1]\n",
    "        \n",
    "        term1 = (start_x - end_x) ** 2\n",
    "        term2 = (start_y - end_y) ** 2\n",
    "        term3 = l ** 2\n",
    "        term4 = 2 * l * (term1 + term2).sqrt()\n",
    "        energy = k / 2 * (term1 + term2 + term3 - term4)\n",
    "        return energy.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_scaled = EnergyLossScaled()\n",
    "criterion = EnergyLossVectorized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_loss = 0\n",
    "pred_loss = 0\n",
    "for idx in tqdm(range(10000, 11000)):\n",
    "    pred, loss = evaluate(model, data_list[idx], criterion, device)\n",
    "    pos_map = nx.nx_agraph.graphviz_layout(G_list[idx], prog='neato')\n",
    "\n",
    "    pred_mean, pred_std = pred.mean(axis=0), pred.std()\n",
    "    truth = np.array(list(pos_map.values()))\n",
    "    truth_mean, truth_std = truth.mean(axis=0), truth.std()\n",
    "    norm_truth = (truth - truth_mean) / truth_std\n",
    "    scaled_truth = norm_truth * pred_std + pred_mean\n",
    "\n",
    "    truth_loss += criterion(torch.tensor(scaled_truth, device=device), data_list[idx])\n",
    "    pred_loss += criterion(torch.tensor(pred, device=device), data_list[idx])\n",
    "    \n",
    "truth_loss / 1000, pred_loss / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in [10898, 10904]:#tqdm(range(10000, 11000)):\n",
    "    data, G = data_list[idx], G_list[idx]\n",
    "    edge_attr = data.edge_attr\n",
    "    pred, loss = evaluate(model, data, criterion, device)\n",
    "    pos_map = nx.nx_agraph.graphviz_layout(G, prog='neato')\n",
    "    truth = np.array(list(pos_map.values()))\n",
    "\n",
    "    start, end, n_nodes = node2edge(torch.tensor(truth, device=device), data)\n",
    "    w = edge_attr[:, 1]\n",
    "    d = edge_attr[:, 0]\n",
    "\n",
    "    u2 = ((start - end) ** 2).sum(dim=1)\n",
    "\n",
    "    s = (w * d * u2.sqrt()).sum() / (w * u2).sum()\n",
    "\n",
    "    loss_gt = criterion_scaled(torch.tensor(truth, device=device), data, s)\n",
    "\n",
    "    print(loss, loss_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, criterion, device, idx):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        pred = model(data).detach()\n",
    "        loss = criterion(pred,data).cpu().numpy()\n",
    "        loss = round(float(loss),2)\n",
    "    return pred.cpu().numpy(), loss\n",
    "\n",
    "def graph_vis(G, node_pos):\n",
    "    i = 0\n",
    "    for n, p in node_pos:\n",
    "        node = 'n' +str(i)\n",
    "        G.nodes[node]['pos'] = (n,p)\n",
    "        i += 1\n",
    "    pos = nx.get_node_attributes(G,'pos')\n",
    "    plt.figure()\n",
    "    nx.draw(G, pos)\n",
    "    \n",
    "for test_idx in tqdm(list(range(10000, len(data_list)))):\n",
    "    G_vis = G_list[test_idx]\n",
    "    node_pos,loss = evaluate(model, data_list[test_idx],criterion,device, test_idx)\n",
    "    if loss > 10000:\n",
    "        print(test_idx, loss, data_list[test_idx].num_nodes)\n",
    "        graph_vis(G_vis, node_pos) \n",
    "        node_pos = nx.nx_agraph.graphviz_layout(G_vis, prog='neato')\n",
    "        plt.figure()\n",
    "        nx.draw(G_vis, node_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval with Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10117\n",
    "pred, loss, sloss, aloss = evaluate(model, data_list[idx], criterion, device, output_components=True, reduction=umap_project)\n",
    "graph_vis(G_list[idx], pred, f'composite_umap_{idx}_loss_{sloss}_{aloss}.png')\n",
    "print(sloss, aloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "losseses = []\n",
    "folder_name = f'{config.name}_{config.test.name}_iterative'\n",
    "if not os.path.isdir(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "for test_idx in tqdm(range(10000, 10500)):\n",
    "    G_vis = G_list[test_idx]\n",
    "#     node_pos = nx.nx_agraph.graphviz_layout(G_vis, prog='neato')\n",
    "#     plt.figure()\n",
    "#     nx.draw(G_vis, node_pos)\n",
    "#     plt.savefig(f'{folder_name}/{test_idx}.png')\n",
    "    losses = []\n",
    "    for i in range(iterations):\n",
    "        node_pos, loss, stress, angle = evaluate(model, data_list[test_idx], criterion, device, output_components=True, with_initial_pos=True) \n",
    "        data_list[test_idx].x = torch.tensor(node_pos,dtype=torch.float)\n",
    "        losses += [loss]\n",
    "    losseses += [losses]\n",
    "    graph_vis(G_vis, node_pos, f'{folder_name}/{config.test.out_prefix}_iter_model_{test_idx}_{stress}_{angle}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bins, _ = plt.hist(np.array(losseses).std(axis=1), bins=10)\n",
    "plt.clf()\n",
    "logbins = np.logspace(np.log10(bins[0]),np.log10(bins[-1]),len(bins))\n",
    "count, bins, _ = plt.hist(np.array(losseses).std(axis=1), bins=logbins, rwidth=0.5, log=False)\n",
    "plt.xscale('log')\n",
    "plt.title('Distribution of std(loss)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2e}'.format\n",
    "pd.DataFrame([bins[:-1], bins[1:], count], index=['min', 'max', 'count']).T.astype({'count': 'int64'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f'../ckpt_{config.name}/epoch_{config.test.epoch}.pt', map_location=torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, data = G_list[0], data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = model(data, output_hidden=True, numpy=True)[1:10]\n",
    "projected = list(map(pca_project, hidden))\n",
    "for i in range(9):\n",
    "    graph_vis(G, projected[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1,2,3]).square()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0536ce9bc3f7413c9aaaccdb942ceda3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "description": "[epoch 1/None]:   0%",
       "layout": "IPY_MODEL_122aa28f723842018b2aba6802675a60",
       "max": 79,
       "style": "IPY_MODEL_54813422df6d4eb1a5380611acb5eb15"
      }
     },
     "086192cbe824486cb4ee19c23d04a497": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "122aa28f723842018b2aba6802675a60": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1597c299adb0403a8d577aa1c9fc8e4f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "197ea17d03634494969fad9346349f5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2acdfa8e1eba4acb8ccc8d88f5c2e63e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1597c299adb0403a8d577aa1c9fc8e4f",
       "style": "IPY_MODEL_2bc14ab711234c9e8498572188681c8a",
       "value": " 1/79 [00:34&lt;44:28, 34.21s/it, loss=4.03e+3]"
      }
     },
     "2bc14ab711234c9e8498572188681c8a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "38e765463bde4ed1b4bd4ceb6c527a88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_7defe8fd0e7f4201b02a4761c71dbc0b",
        "IPY_MODEL_2acdfa8e1eba4acb8ccc8d88f5c2e63e"
       ],
       "layout": "IPY_MODEL_b1b6f9ac9b1841cf8310c9412b64f97f"
      }
     },
     "43f547f90b7541b3b4a4e8b340a06c1a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "54813422df6d4eb1a5380611acb5eb15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "58d0c4606d0f4f4a9abe86934a0ef0c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f63dd56e03964a5b90919d7f3b383964",
        "IPY_MODEL_77301086654c431ead8952f276afa9ff"
       ],
       "layout": "IPY_MODEL_642cd5d1489d49b6bca9ba90c838d18e"
      }
     },
     "58fe0be13a3d4273a0bf2ae548a5e261": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "63e8f14510824d34825f61f95cf7246f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fef069154da845da823f477580507146",
       "style": "IPY_MODEL_8903052706b943c88776581cbba16acc",
       "value": " 0/79 [00:15&lt;?, ?it/s]"
      }
     },
     "642cd5d1489d49b6bca9ba90c838d18e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "77301086654c431ead8952f276afa9ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_58fe0be13a3d4273a0bf2ae548a5e261",
       "style": "IPY_MODEL_197ea17d03634494969fad9346349f5c",
       "value": " 0/79 [00:00&lt;?, ?it/s]"
      }
     },
     "7defe8fd0e7f4201b02a4761c71dbc0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "description": "[epoch 1/None]:   1%",
       "layout": "IPY_MODEL_086192cbe824486cb4ee19c23d04a497",
       "max": 79,
       "style": "IPY_MODEL_8f07739637924c36ab794cc4ab70bd90",
       "value": 1
      }
     },
     "85bddf84d52e473bab35f3aabc5099a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8903052706b943c88776581cbba16acc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8f07739637924c36ab794cc4ab70bd90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "a177c0f9c4f04686908cdd2ec7205510": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "b1b6f9ac9b1841cf8310c9412b64f97f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f63dd56e03964a5b90919d7f3b383964": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "description": "[epoch 1/None]:   0%",
       "layout": "IPY_MODEL_85bddf84d52e473bab35f3aabc5099a7",
       "max": 79,
       "style": "IPY_MODEL_a177c0f9c4f04686908cdd2ec7205510"
      }
     },
     "fea2f644e4944a11a5f66de244a0ecd0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_0536ce9bc3f7413c9aaaccdb942ceda3",
        "IPY_MODEL_63e8f14510824d34825f61f95cf7246f"
       ],
       "layout": "IPY_MODEL_43f547f90b7541b3b4a4e8b340a06c1a"
      }
     },
     "fef069154da845da823f477580507146": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
